{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66dec99f",
   "metadata": {},
   "source": [
    "## Midterm Review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c66abc",
   "metadata": {},
   "source": [
    "1. 미리 주어진 문장들의 토큰 집합 생성 코드 블록(공백 기준으로 쪼개진 단어)\n",
    "    \n",
    "    (문장 내 . 생략, 대소문자 구분 X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "50bbad0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lies', 'gold.', 'opportunity.', 'with', 'dog.', 'read', 'quick', 'books.', 'a', 'all', 'in', 'step.', 'miles', 'journey', 'not', 'middle', 'brown', 'over', 'to', 'the', 'is', 'begins', 'of', 'difficulty', 'likes', 'thousand', 'lazy', 'single', 'she', 'fox', 'jumps', 'glitters', 'that'}\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "sentences = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"A journey of a thousand miles begins with a single step.\",\n",
    "    \"All that glitters is not gold.\",    \n",
    "    \"In the middle of difficulty lies opportunity.\",\n",
    "    \"She likes to read books.\"\n",
    "]\n",
    "\n",
    "\n",
    "total_terms = set() #집합 생성\n",
    "\n",
    "for i in sentences: #주어진 문장 내에서 반복\n",
    "    preprocessed_sentences = i.lower().split(\" \") #소문자화하고 공백 기준으로 쪼개어 preprocessed_sentences에 저장\n",
    "    for j in preprocessed_sentences: #소문자화하고 공백 기준으로 쪼개어진 단어 내에서 반복\n",
    "        total_terms.add(j) #total_terms 집합에 소문자화,공백기준으로 쪼개어진 단어들 추가\n",
    "\n",
    "        \n",
    "print(total_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ded047",
   "metadata": {},
   "source": [
    "2. 토큰 별 단어 빈도를 계산하는 코드 블록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f9634af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----TF dictionary-----\n",
      "{'the': 3, 'quick': 1, 'brown': 1, 'fox': 1, 'jumps': 1, 'over': 1, 'lazy': 1, 'dog.': 1, 'a': 3, 'journey': 1, 'of': 2, 'thousand': 1, 'miles': 1, 'begins': 1, 'with': 1, 'single': 1, 'step.': 1, 'all': 1, 'that': 1, 'glitters': 1, 'is': 1, 'not': 1, 'gold.': 1, 'in': 1, 'middle': 1, 'difficulty': 1, 'lies': 1, 'opportunity.': 1, 'she': 1, 'likes': 1, 'to': 1, 'read': 1, 'books.': 1}\n"
     ]
    }
   ],
   "source": [
    "term_frequency_dict = {} # 토큰 별 단어 빈도 저장할 딕셔너리\n",
    "\n",
    "for i in sentences: #주어진 문장 내에서 반복\n",
    "    preprocessed_sentences = i.lower().split(\" \") #소문자화하고 공백 기준으로 쪼개어 preprocessed_sentences에 저장\n",
    "    for j in preprocessed_sentences: #소문자화하고 공백 기준으로 쪼개어진 단어 내에서 반복\n",
    "        total_terms.add(j)  #total_terms 집합에 소문자화,공백기준으로 쪼개어진 단어들 추가\n",
    "\n",
    "        if j in term_frequency_dict: #토큰 j가 딕셔너리에 있다면\n",
    "            term_frequency_dict[j] += 1 #빈도수 1 증가\n",
    "        else: #딕셔너리에 없다면\n",
    "            term_frequency_dict[j] = 1 #새로운 토큰으로 추가하고 빈도수 1로 설정\n",
    "    \n",
    "\n",
    "# 토큰 빈도 출력\n",
    "print(\"-----TF dictionary-----\")\n",
    "print(term_frequency_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a987cd0a",
   "metadata": {},
   "source": [
    "3. 1~3번째로 많이 나타난 단어와 빈도를 출력하는 코드 블록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bb1785e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Top-3 TF terms --\n",
      "1 the 3\n",
      "2 a 3\n",
      "3 of 2\n"
     ]
    }
   ],
   "source": [
    "# 단어 빈도를 기준으로 내림차순으로 정렬\n",
    "sorted_word_list = sorted(term_frequency_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "print(\"----- Top-3 TF terms --\")\n",
    "\n",
    "#Top-3 토큰 빈도를 갖는 단어의 순위, 단어, 빈도 출력 \n",
    "for i in range(3): #상위 3개 출력 => 정렬된 리스트에서 3번 반복\n",
    "    word, count = sorted_word_list[i]\n",
    "    print(i+1, word, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da71fd5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
